---
comments: true
date: 2010-01-29 12:51:52
layout: post
slug: the-efficiency-paradox
title: The Efficiency Paradox
wordpress_id: 369
categories:
- Business
- cloud
- General
---

I'm a pretty firm believer in Infrastructure-as-a-Service, and I spend a lot of time thinking about better ways to squeeze more efficiency out of data centers and IT operations. A lot of the lower hanging fruit involves savings in power utilization, reducing cooling costs, and virtualizing hardware; Â getting less to do more. Economies of scale, and automated controls mean you can be extremely price competitive, and for end users that can lead to greater savings.

Popular wisdom suggests that this would mean we get to save something; We conserve energy because were powering less servers.

It turns out the opposite is true.

[Jevons Paradox ](http://en.wikipedia.org/wiki/Jevons_paradox)explains the effect that technological progress has on reducing prices of a resource, only to increase the actual consumption of that resource. Typically this applied a lot to the Oil industry, and its a rather well understood phenomenon, but the same thing applies to Network and Computing infrastructure.

Bandwidth is perhaps the easiest example of Jevons Paradox. Back when a couple megs of throughput cost you $1500 a month, you would find ways to reduce and conserve that bandwidth as much as possible. Technology has progressed to the point where some lucky individuals can get a LAN quality connection for as little as $30 dollars. It's obvious that the cost for bandwidth has dropped through the floor. While that kind of progress should lead to greater efficiencies, it simply doesn't work out that way. We dont conserve those pipes - we just use more of them.

[caption id="" align="alignnone" width="326" caption="Elastic Demand for Work: A doubling of fuel efficiency more than doubles the amount of work demanded, increasing the amount of fuel used. Jevons Paradox occurs "]![](http://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/JevonsParadoxA.png/326px-JevonsParadoxA.png)[/caption]

The same thing is happening in utility computing.The cost of computing is quickly becoming too cheap for us to save any energy, or to force us to squeeze more out of a system. While at [layerboom](http://layerboom.com) we build advanced systems that can generate more revenue per physical server, the end result for utility operators is that they will sell more units. For them, this is a totally acceptable solution (and I wont complain either!). However, it has some dire implications for energy usage and conservation. Most of this infrastructure is running 24x7. Idle or not.

In North America, the infrastruture required to run the internet consumes about 10% of our electricity. Do our Data Centers need to get bigger? Or do we really need to start figuring out how to not only make these pieces of infrastructure more efficient, but find a way to ensure those efficiencies at least counter the growth in the system?
